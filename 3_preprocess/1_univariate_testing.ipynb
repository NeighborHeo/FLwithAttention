{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJ_PATH = Path().cwd().parent\n",
    "# DATA_PATH = PROJ_PATH.joinpath('data')\n",
    "# In[ ]:\n",
    "# ** loading path info **\n",
    "current_dir = pathlib.Path.cwd()\n",
    "parent_dir = current_dir.parent\n",
    "curr_file_name = os.path.splitext(os.path.basename(os.path.abspath('')))[0]\n",
    "data_dir = pathlib.Path('{}/data/eicu/'.format(parent_dir))\n",
    "data_ps_dir = data_dir.joinpath('ps')\n",
    "pathlib.Path.mkdir(data_dir, mode=0o777, parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_list = ['MSICU', 'CTICU', 'SICU', 'CCUCTICU', 'MICU', 'NICU', 'CICU', 'CSICU']\n",
    "icu_df_dict = {}\n",
    "for icu in icu_list:\n",
    "    icu_df_dict[icu] = pd.read_feather('{}/{}_df.feather'.format(data_ps_dir, icu))\n",
    "    print('icu : ', icu, ' len(columns) : ', len(icu_df_dict[icu].columns), ' len(df) : ', len(icu_df_dict[icu]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing(df):\n",
    "    drop_list = ['apacheadmissiondx', 'hospitaladmittime24', 'hospitaldischargelocation', 'hospitaldischargetime24', 'patienthealthsystemstayid', \n",
    "                'uniquepid', 'unitadmittime24', 'unitdischargelocation', 'unitdischargestatus', 'unitdischargetime24', 'unittype']\n",
    "    df.drop(columns = list(set(df.columns)&set(drop_list)), inplace=True)\n",
    "    encoder = {}\n",
    "    encoder['gender'] = {\"M\":1, \"F\":0, \"Female\":0, \"Male\":1}\n",
    "    encoder['외국인여부'] = {\"N\":0, \"Y\":1, 'K':np.nan}\n",
    "    encoder['death'] = {'Alive':0, \"Expired\":1}\n",
    "    encoder['ethnicity'] = {\"African American\":0, \"Caucasian\":1,\"Hispanic\":2, \"Asian\":3, 'Native American':4, 'Other/Unknown':5}\n",
    "    df_unitadmitsource = {col : idx for idx, col in enumerate(df.unitadmitsource.unique())}\n",
    "    encoder['unitadmitsource'] = df_unitadmitsource\n",
    "    df_unitstaytype = {col : idx for idx, col in enumerate(df.unitstaytype.unique())}\n",
    "    encoder['unitstaytype'] = df_unitstaytype\n",
    "    df_hospitaladmitsource = {col : idx for idx, col in enumerate(df.hospitaladmitsource.unique())}\n",
    "    encoder['hospitaladmitsource'] = df_hospitaladmitsource\n",
    "    encoder['hospitaldischargestatus'] = {\"Expired\":1, \"Alive\":0}\n",
    "    encoder[\"death\"] = {\"Alive\":0, \"Expired\":1}\n",
    "    df = df.replace(encoder)\n",
    "    df['age'] = df.age.str.replace('>','').astype('float')\n",
    "    df['gender'] = df.gender.replace('Other|Unknown',np.nan, regex=True)\n",
    "    # df = df.dropna(subset=['gender', 'age'], axis=0)\n",
    "    df = df.dropna(axis=0)\n",
    "    # df = df.rename(columns = {'hospitaldischargestatus':'death', \"admissionheight\":'height','admissionweight':'weight', 'meanbp':'bp'})\n",
    "    # # df.head()\n",
    "    # df = df.rename(columns = {'patientunitstayid':'연구등록번호'})\n",
    "    return df\n",
    "\n",
    "for icu in icu_list:\n",
    "    print(icu)\n",
    "    icu_df_dict[icu] = parsing(icu_df_dict[icu])\n",
    "    print('icu : ', icu, ' len(columns) : ', len(icu_df_dict[icu].columns), ' len(df) : ', len(icu_df_dict[icu]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HICU = pd.read_feather(data_dir.joinpath('hicu.feather'))\n",
    "HICU['bp'] = HICU.bp.str.extract('(\\d{2,3})/(\\d{2,3})').apply(lambda x : (float(x[0]) + 2*float(x[1]))/3, axis=1)\n",
    "HICU['temperature'] = HICU.temperature.str.replace(',','.').str.extract(\"(\\d{2}[.,\\,]\\d{1,2}|\\d{2})\").astype('float')\n",
    "HICU['heartrate'] = HICU.heartrate.str.extract(\"(\\d{2,3})\")\n",
    "HICU['respiratoryrate'] = HICU.respiratoryrate.str.extract(\"(\\d{2})\")\n",
    "import numpy as np\n",
    "encoder = {}\n",
    "encoder['gender'] = {\"M\":1, \"F\":0, \"Female\":0, \"Male\":1}\n",
    "encoder['외국인여부'] = {\"N\":0, \"Y\":1, 'K':np.nan}\n",
    "encoder['death'] = {'Alive':0, \"Expired\":1}\n",
    "HICU = HICU.replace(encoder)\n",
    "HICU.외국인여부.unique()\n",
    "HICU = HICU.astype({'age':'float32', 'height':\"float\", 'weight':\"float\", 'heartrate':\"float\", \"respiratoryrate\":\"float\", \n",
    "                                     \"신장Z\":'float', \"신장P\":\"float\", '체중Z':\"float\", \"체중P\":'float', '체표면적':\"float\",\n",
    "                                     \"death\":'float'})\n",
    "HICU['외국인여부'] = HICU.외국인여부.fillna(2)\n",
    "death = HICU['death']\n",
    "HICU = HICU.groupby('death').transform(lambda group : group.fillna(group.mean()))\n",
    "HICU['death'] = death\n",
    "HICU.to_feather(data_dir.joinpath('ps','HICU.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 파씽 진행\n",
    "- common feature는 비슷한 형식으로 encoding 진행\n",
    "- specific feature에 대해서는 dummy encoding을 진행해야 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing with MICU, SICU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free text로 되어 있는 admissiondx는 쓰지 않는다. in eICU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common Feature, Specific Feature 추리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_features = set(HICU.columns)\n",
    "for icu in icu_list:\n",
    "    common_features = common_features & set(icu_df_dict[icu].columns)\n",
    "common_features.remove('death')\n",
    "common_features.remove('연구등록번호')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_features = {}\n",
    "for icu in icu_list:\n",
    "    specific_features[icu] = set(icu_df_dict[icu].columns) - common_features - set(['연구등록번호', 'death'])\n",
    "    print(icu, 'specific : ', len(specific_features[icu]) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_features['HICU'] = set(HICU.columns) - common_features - set(['연구등록번호', 'death'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def _min_max_scaler(df):\n",
    "    min_max_scalar = MinMaxScaler()\n",
    "    fitted = min_max_scalar.fit_transform(df[df.columns[1:]])\n",
    "    df[df.columns[1:]] = fitted\n",
    "    return df\n",
    "\n",
    "for icu in icu_list:\n",
    "    data_ps2_dir = pathlib.Path.joinpath(data_dir, 'ps2')\n",
    "    pathlib.Path.mkdir(data_ps2_dir, mode=0o777, parents=True, exist_ok=True)\n",
    "    icu_df_dict[icu].reset_index(drop=True, inplace=True)\n",
    "    icu_df_dict[icu] = _min_max_scaler(icu_df_dict[icu])\n",
    "    icu_df_dict[icu].to_feather('{}/{}_df.feather'.format(data_ps2_dir, icu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HICU.to_feather('{}/{}_df.feather'.format(data_ps2_dir, 'HICU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _min_max_scaler(df):\n",
    "    min_max_scalar = MinMaxScaler()\n",
    "    fitted = min_max_scalar.fit_transform(df[df.columns[1:]])\n",
    "    df[df.columns[1:]] = fitted\n",
    "    return df\n",
    "\n",
    "def collect_significant_variables(df, outcome, variables):\n",
    "    X = df[variables]\n",
    "    y = df[outcome]\n",
    "    lasso = Lasso(alpha=0.003)\n",
    "    # print(X)\n",
    "    lasso.fit(X, y)\n",
    "    print(lasso.coef_)\n",
    "    importance = np.abs(lasso.coef_)\n",
    "    selected_features = np.array(X.columns)[importance > 0]\n",
    "    print(selected_features)\n",
    "    print(len(selected_features))\n",
    "    return selected_features\n",
    "\n",
    "# for icu in icu_list:\n",
    "#     icu_df_dict[icu] = _min_max_scaler(icu_df_dict[icu])\n",
    "\n",
    "for icu in icu_list:\n",
    "    icu_df_dict[icu] = pd.read_feather('{}/{}.feather'.format(data_dir, icu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icu_df_dict[icu]['hospitaldischargestatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = {}    \n",
    "for icu in icu_list:\n",
    "    outcome = 'death'\n",
    "    selected_features[icu] = collect_significant_variables(icu_df_dict[icu], outcome, specific_features[icu])\n",
    "    with open(data_ps2_dir.joinpath('{}_selected.pkl'.format(icu)),'wb') as f:\n",
    "        pickle.dump(selected_features[icu], f)\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(data_ps2_dir.joinpath('feature_book.yaml'),'w') as f:\n",
    "    yaml.dump(selected_features, f, allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Specific variables for eICU datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_significant_variables(df, outcome, variables):\n",
    "    X = df[variables]\n",
    "    y = df[outcome]\n",
    "    lasso = Lasso(alpha=0.0010)\n",
    "    # print(X)\n",
    "    lasso.fit(X, y)\n",
    "    print(lasso.coef_)\n",
    "    importance = np.abs(lasso.coef_)\n",
    "    selected_features = np.array(X.columns)[importance > 0]\n",
    "    print(selected_features)\n",
    "    print(len(selected_features))\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df = pd.DataFrame()\n",
    "for icu in icu_list:\n",
    "    concat_df = pd.concat([concat_df, icu_df_dict[icu]], axis=0)\n",
    "feature_all = list(set(concat_df.columns) - set(['patientunitstayid', 'hospitaldischargestatus']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_df['hospitaldischargestatus'].hist()\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x ='hospitaldischargestatus', data = concat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.hospitaldischargestatus.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = collect_significant_variables(concat_df, \"hospitaldischargestatus\", feature_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "337931fc7d6bb9b763b2fb479d60ecd1f038a441c6a2b8bddc89fff079691cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
